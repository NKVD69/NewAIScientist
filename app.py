import streamlit as st
import asyncio
import pandas as pd
import json
import os
from datetime import datetime
import plotly.express as px
from dataclasses import asdict

# Import du backend
from co_scientist import CoScientist, ResearchGoal, Hypothesis

CONFIG_FILE = "app_config.json"

def load_config():
    """Load configuration from file"""
    if os.path.exists(CONFIG_FILE):
        try:
            with open(CONFIG_FILE, "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception as e:
            st.error(f"Erreur lors du chargement de la config: {e}")
    return {}

def save_config(params):
    """Save configuration to file"""
    try:
        # Load existing to avoid overwriting everything if we only save partials
        config = load_config()
        config.update(params)
        with open(CONFIG_FILE, "w", encoding="utf-8") as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
    except Exception as e:
        print(f"Erreur lors de la sauvegarde de la config: {e}")

# Load initial config
config = load_config()

# Configuration de la page
st.set_page_config(
    page_title="AI Co-Scientist Dashboard",
    page_icon="üß¨",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Styles CSS personnalis√©s pour un look plus moderne
st.markdown("""
    <style>
    .stApp {
        background-color: #0e1117;
    }
    .metric-card {
        background-color: #262730;
        border: 1px solid #464b5c;
        padding: 20px;
        border-radius: 10px;
        color: white;
    }
    .hypothesis-card {
        background-color: #1f2937;
        padding: 20px;
        border-radius: 10px;
        margin-bottom: 15px;
        border-left: 5px solid #3b82f6;
    }
    .paper-card {
        background-color: #2d3748;
        padding: 15px;
        border-radius: 8px;
        margin-bottom: 10px;
        border: 1px solid #4a5568;
    }
    </style>
    """, unsafe_allow_html=True)

# --- SIDEBAR: CONFIGURATION ---
with st.sidebar:
    st.header("‚öôÔ∏è Configuration")
    
    # LLM Settings
    st.subheader("LLM Settings")
    use_local_llm = st.checkbox("Utiliser un LLM local", 
                                value=config.get("use_local_llm", True),
                                key="persist_use_local_llm",
                                on_change=lambda: save_config({"use_local_llm": st.session_state.persist_use_local_llm}))
    
    if use_local_llm:
        llm_base_url = st.text_input("URL du LLM", 
                                   value=config.get("llm_base_url", "http://127.0.0.1:1234/v1"),
                                   key="persist_llm_base_url",
                                   on_change=lambda: save_config({"llm_base_url": st.session_state.persist_llm_base_url}))
        llm_model_name = st.text_input("Nom du mod√®le", 
                                     value=config.get("llm_model_name", "openai/gpt-oss-20b"),
                                     key="persist_llm_model_name",
                                     on_change=lambda: save_config({"llm_model_name": st.session_state.persist_llm_model_name}))
        
        # Mise √† jour des variables d'environnement pour le backend
        os.environ["OPENAI_API_BASE"] = llm_base_url
        os.environ["OPENAI_API_KEY"] = "lm-studio"  # Dummy key for local
        os.environ["OPENAI_MODEL_NAME"] = llm_model_name
        
        # BOUTON DE TEST DE CONNEXION
        if st.button("üì° Tester la connexion"):
            try:
                import openai
                client = openai.OpenAI(base_url=llm_base_url, api_key="lm-studio")
                # Test simple : lister les mod√®les ou faire un petit chat
                with st.spinner("Ping du serveur..."):
                    models = client.models.list()
                    st.success(f"Connexion r√©ussie ! Serveur actif.")
            except Exception as e:
                st.error(f"√âchec de connexion : {e}")
    else:
        st.warning("Mode Simulation activ√©")

    st.divider()
    st.subheader("Param√®tres de Recherche")
    num_hypotheses = st.slider("Nombre d'hypoth√®ses", 3, 20, 
                                value=config.get("num_hypotheses", 5),
                                key="persist_num_hyp",
                                on_change=lambda: save_config({"num_hypotheses": st.session_state.persist_num_hyp}))
    num_iterations = st.slider("Nombre d'it√©rations", 1, 10, 
                                value=config.get("num_iterations", 3),
                                key="persist_num_iter",
                                on_change=lambda: save_config({"num_iterations": st.session_state.persist_num_iter}))
    
    st.subheader("Param√®tres Sources")
    max_papers = st.slider("Max Papiers/Source", 3, 100, 
                            value=config.get("max_papers", 5),
                            key="persist_max_papers",
                            on_change=lambda: save_config({"max_papers": st.session_state.persist_max_papers}))
    
    st.divider()
    
    # RAG System Settings
    enable_rag = st.checkbox("Activer RAG (t√©l√©chargement & analyse PDF)", 
                              value=config.get("enable_rag", True),
                              key="persist_enable_rag",
                              on_change=lambda: save_config({"enable_rag": st.session_state.persist_enable_rag}),
                              help="T√©l√©charge les PDFs et effectue une recherche s√©mantique avanc√©e")
    
    # Display RAG stats if available
    if 'results' in st.session_state and st.session_state.results is not None:
        try:
            rag_stats = st.session_state.results.literature_agent.get_rag_stats()
            if rag_stats['status'] == 'ready':
                st.success(f"üß† RAG actif: {rag_stats['total_chunks']} chunks index√©s")
            elif rag_stats['status'] == 'disabled':
                st.info("‚ÑπÔ∏è RAG d√©sactiv√©")
        except (AttributeError, KeyError):
            pass  # Not initialized yet
    
    st.divider()
    st.info("AI Co-Scientist v1.3\nBased on Google DeepMind Research")

# --- CONFIGURATION & SESSION STATE ---
# Initialize session state for widgets if not present to avoid value/key conflicts
if "persist_goal_title" not in st.session_state:
    st.session_state.persist_goal_title = config.get("goal_title", "Drug Repurposing for AML")
if "persist_goal_domain" not in st.session_state:
    st.session_state.persist_goal_domain = config.get("goal_domain", "Biomedicine/Oncology")
if "persist_goal_desc" not in st.session_state:
    st.session_state.persist_goal_desc = config.get("goal_desc", "Identify FDA-approved drugs that could be repurposed for acute myeloid leukemia (AML) treatment.")
if "persist_sources" not in st.session_state:
    # Bug 5 fix integration: resolve stale sources
    st.session_state.persist_sources = config.get("source_type", ["arxiv", "pubmed"])
if "persist_constraints" not in st.session_state:
    st.session_state.persist_constraints = config.get("constraints", "Only FDA-approved drugs\nMust have mechanism documentation")

# --- MAIN CONTENT ---

st.title("üß¨ AI Co-Scientist Workbench")
st.markdown("### Assistant de d√©couverte scientifique multi-agents")

# Initialisation de l'√©tat de session
if 'co_scientist' not in st.session_state:
    st.session_state.co_scientist = None
if 'results' not in st.session_state:
    st.session_state.results = None
if 'is_running' not in st.session_state:
    st.session_state.is_running = False

# --- SECTION 1: DEFINITION DE L'OBJECTIF ---
with st.expander("üéØ D√©finir l'Objectif de Recherche", expanded=not st.session_state.is_running):
    # Appliquer les suggestions de l'Auto-d√©tection AVANT que les widgets soient cr√©√©s
    if "suggested_domain" in st.session_state:
        st.session_state.persist_goal_domain = st.session_state.suggested_domain
        del st.session_state.suggested_domain
    if "suggested_sources" in st.session_state:
        st.session_state.persist_sources = st.session_state.suggested_sources
        del st.session_state.suggested_sources

    col1, col2 = st.columns([1, 1])
    
    with col1:
        goal_title = st.text_input("Titre de la Recherche", 
                                 key="persist_goal_title",
                                 on_change=lambda: save_config({"goal_title": st.session_state.persist_goal_title}))
        
        # Domain Auto-detection
        col_dom, col_btn = st.columns([3, 1])
        with col_dom:
            goal_domain = st.text_input("Domaine Scientifique", 
                                      key="persist_goal_domain")
        with col_btn:
            st.write("") # Spacer
            if st.button("ü™Ñ Auto", help="D√©tecter le domaine et les sources via IA"):
                with st.spinner("Analyse..."):
                    try:
                        # Temporary CoScientist instance for analysis
                        temp_cs = CoScientist(use_local_llm=use_local_llm, enable_rag=enable_rag) # Improvement 6
                        # Improvement 5: Asyncio fix
                        loop = asyncio.new_event_loop()
                        asyncio.set_event_loop(loop)
                        analysis = loop.run_until_complete(temp_cs.analyze_research_description(st.session_state.persist_goal_desc))
                        
                        if analysis:
                            suggested_domains = ", ".join(analysis.get("domains", []))
                            suggested_dbs = analysis.get("databases", [])
                            
                            # Stocker temporairement pour application au prochain rerun
                            st.session_state.suggested_domain = suggested_domains
                            st.session_state.suggested_sources = [s for s in suggested_dbs if s in ["arxiv", "pubmed", "biorxiv", "ieee_xplore", "scopus", "google_scholar", "semantic_scholar"]]
                            st.rerun()
                    except Exception as e:
                        st.error(f"Erreur d'analyse: {e}")
    
    with col2:
        goal_desc = st.text_area("Description D√©taill√©e", 
                               height=100,
                               key="persist_goal_desc")
        
        # Dynamic Database Selection
        all_sources = ["arxiv", "pubmed", "biorxiv", "ieee_xplore", "scopus", "google_scholar", "semantic_scholar"]
        # Bug 5: Logic handled by initialization above
        selected_sources = st.multiselect("Bases de donn√©es pertinentes", 
                                        options=all_sources,
                                        key="persist_sources",
                                        on_change=lambda: save_config({"source_type": st.session_state.persist_sources}))

    constraints = st.text_area("Contraintes (une par ligne)", 
                             key="persist_constraints")
    
    st.markdown("---")
    submit_btn = st.button("Lancer la Recherche", type="primary", use_container_width=True)

# --- LOGIQUE D'EXECUTION ---
async def run_research_cycle():
    # Initialisation
    # Improvement 6: Pass enable_rag to CoScientist
    cs = CoScientist(use_local_llm=use_local_llm, enable_rag=enable_rag)
    st.session_state.co_scientist = cs
    
    # Setup Goal
    constraint_list = [c.strip() for c in constraints.split('\n') if c.strip()]
    await cs.initialize_research_goal(
        title=goal_title,
        description=goal_desc,
        domain=goal_domain,
        constraints=constraint_list
    )
    
    # Container pour l'affichage progressif
    status_container = st.status("D√©marrage du workflow...", expanded=True)
    
    try:
        # 0. Recherche Bibliographique
        status_container.write(f"üìö Agent Litt√©rature : Recherche sur {','.join(selected_sources).upper()}...")
        # selected_sources comes from the widget in the sidebar/expander
        papers = await cs.run_literature_search(max_results=max_papers, sources=selected_sources)
        if papers:
            status_container.write(f"‚úÖ {len(papers)} papiers pertinents trouv√©s.")
        else:
            status_container.write("‚ö†Ô∏è Aucun papier trouv√© ou erreur (v√©rifiez votre connexion/d√©pendances).")

        # 1. G√©n√©ration
        status_container.write("üî¨ Agent G√©n√©ration : Cr√©ation des hypoth√®ses (avec contexte)...")
        await cs.run_hypothesis_generation_cycle(num_hypotheses=num_hypotheses)
        status_container.write(f"‚úÖ {num_hypotheses} hypoth√®ses g√©n√©r√©es.")
        
        for i in range(num_iterations):
            status_container.update(label=f"It√©ration {i+1}/{num_iterations} en cours...", state="running")
            
            # 2. Revue
            status_container.write(f"üìù Agent R√©flexion : Revue critique (Cycle {i+1})...")
            await cs.run_review_cycle()
            
            # 3. Proximit√©
            status_container.write(f"üîó Agent Proximit√© : Analyse des similarit√©s (Cycle {i+1})...")
            await cs.proximity_agent.compute_proximity(list(cs.context_memory.hypotheses.values()))
            
            # 4. Tournoi
            status_container.write(f"üèÜ Agent Classement : Tournoi Elo (Cycle {i+1})...")
            await cs.run_tournament_cycle(num_matches=num_hypotheses) # Un match par hypoth√®se environ
            
            # 5. Evolution
            status_container.write(f"üß¨ Agent Evolution : Am√©lioration des id√©es (Cycle {i+1})...")
            await cs.run_evolution_cycle()
            
            # 6. Meta-Review
            status_container.write(f"üéØ Agent Meta-Review : Synth√®se (Cycle {i+1})...")
            await cs.run_meta_review_cycle()
            
        status_container.update(label="Recherche termin√©e !", state="complete", expanded=False)
        st.session_state.results = cs
        
    except Exception as e:
        status_container.update(label="Erreur", state="error")
        st.error(f"Une erreur est survenue: {str(e)}")
    
    if cs.generation_agent.last_error:
        st.warning(f"‚ö†Ô∏è Note: Le g√©n√©rateur a rencontr√© une erreur et a utilis√© la simulation : \n\n{cs.generation_agent.last_error}")


if submit_btn:
    # Save goal fields before running
    save_config({
        "goal_title": goal_title,
        "goal_domain": goal_domain,
        "goal_desc": goal_desc,
        "constraints": constraints
    })
    st.session_state.is_running = True
    asyncio.run(run_research_cycle())
    st.session_state.is_running = False
    st.rerun()

# --- SECTION 2: RESULTATS ---
if st.session_state.results:
    cs = st.session_state.results
    
    # Affichage des erreurs de g√©n√©ration persistantes
    if cs.generation_agent.last_error:
        st.warning(f"‚ö†Ô∏è **Attention : Le g√©n√©rateur a rencontr√© une erreur et a utilis√© la simulation.**\n\n**D√©tail de l'erreur :**\n{cs.generation_agent.last_error}")
    
    hypotheses = list(cs.context_memory.hypotheses.values())
    
    # M√©triques Globales
    st.divider()
    m1, m2, m3, m4 = st.columns(4)
    m1.metric("Hypoth√®ses Totales", len(hypotheses))
    m2.metric("Matchs Tournoi", len(cs.context_memory.tournament_history))
    m3.metric("Revues Effectu√©es", cs.reflection_agent.reviews_completed)
    
    # Meilleure Hypoth√®se
    top_hyp = max(hypotheses, key=lambda h: h.elo_rating)
    m4.metric("Meilleur Elo", f"{top_hyp.elo_rating:.0f}")

    # --- ONGLETS D'ANALYSE ---
    tab1, tab2, tab3, tab4, tab5 = st.tabs(["üèÜ Classement & D√©tails", "üìö Litt√©rature", "üìä Analyses Graphiques", "üìù Meta-Review", "üíæ Export"])
    
    with tab1:
        st.subheader("Classement des Hypoth√®ses")
        
        # Conversion en DataFrame pour affichage propre
        data = []
        for h in hypotheses:
            data.append({
                "ID": h.id,
                "Titre": h.title,
                "Elo": int(h.elo_rating),
                "Nouveaut√©": h.novelty_level,
                "Status": h.status.value,
                "Reviews": len(h.reviews)
            })
        df = pd.DataFrame(data).sort_values("Elo", ascending=False)
        
        # Affichage interactif
        st.dataframe(
            df,
            column_config={
                "Elo": st.column_config.ProgressColumn(
                    "Score Elo",
                    help="Classement relatif",
                    format="%d",
                    min_value=1000,
                    max_value=1600,
                ),
                "Nouveaut√©": st.column_config.TextColumn(
                    "Niveau de Nouveaut√©",
                ),
            },
            hide_index=True,
            use_container_width=True
        )
        
        st.subheader("D√©tails des Hypoth√®ses")
        selected_id = st.selectbox("Choisir une hypoth√®se pour voir les d√©tails", df["ID"].tolist(), format_func=lambda x: df[df["ID"]==x]["Titre"].values[0])
        
        if selected_id:
            h = cs.context_memory.hypotheses[selected_id]
            
            with st.container():
                st.markdown(f"""
                <div class="hypothesis-card">
                    <h3>{h.title}</h3>
                    <p style="color: #6c757d; font-style: italic; margin-bottom: 15px;">{h.description}</p>
                    <div style="background-color: rgba(66, 133, 244, 0.1); padding: 10px; border-radius: 5px; margin-bottom: 15px;">
                        <strong>üß† Raisonnement & Formulation:</strong><br>
                        {h.reasoning if h.reasoning else "Donn√©es non disponibles pour cette version."}
                    </div>
                    <p><strong>‚öôÔ∏è M√©canisme Scientifique:</strong><br>{h.mechanism}</p>
                </div>
                """, unsafe_allow_html=True)
                
                c1, c2 = st.columns(2)
                with c1:
                    st.markdown("#### üß™ Pr√©dictions Testables")
                    if h.testable_predictions:
                        for p in h.testable_predictions:
                            st.markdown(f"- {p}")
                    else:
                        st.info("Aucune pr√©diction g√©n√©r√©e.")
                
                with c2:
                    st.markdown("#### üìö Preuves & Sources")
                    # Affichage combin√© des preuves et des papiers cit√©s
                    if h.grounding_evidence:
                        for g in h.grounding_evidence:
                            st.markdown(f"- {g}")
                    else:
                        st.info("Aucune preuve sp√©cifique g√©n√©r√©e.")
                        
                    if h.cited_papers:
                        st.markdown("**R√©f√©rences:**")
                        for p in h.cited_papers:
                            st.markdown(f"- *{p}*")
                
                if h.reviews:
                    st.markdown("#### üßê Derni√®res Critiques")
                    last_review = h.reviews[-1]
                    st.info(f"**Feedback:** {last_review.feedback}")
                    
                    # Scores sous forme de jauges
                    sc1, sc2, sc3, sc4 = st.columns(4)
                    sc1.progress(last_review.correctness_score, text="Correctness")
                    sc2.progress(last_review.novelty_score, text="Novelty")
                    sc3.progress(last_review.testability_score, text="Testability")
                    sc4.progress(last_review.quality_score, text="Quality")

    with tab2:
        # Bug 2: Fix undefined source_type
        sources_display = ", ".join(selected_sources).upper() if 'selected_sources' in locals() else "S√âLECTIONN√âES"
        st.subheader(f"Contexte Bibliographique ({sources_display})")
        # Acc√®s direct √† la m√©moire du contexte
        papers = cs.context_memory.literature_context
        if papers:
            for p in papers:
                st.markdown(f"""
                <div class="paper-card">
                    <h4><a href="{p['url']}" target="_blank" style="color: #60a5fa; text-decoration: none;">{p['title']}</a></h4>
                    <p style="font-size: 0.9em; color: #cbd5e1;">üìÖ {p['published']} | ‚úçÔ∏è {', '.join(p['authors'][:3])}...</p>
                    <p style="font-size: 0.95em;">{p['summary']}</p>
                    <p style="font-size: 0.8em; color: #94a3b8;">Source: {p.get('source', 'Unknown')}</p>
                </div>
                """, unsafe_allow_html=True)
        else:
            st.info("Aucun papier trouv√© ou recherche d√©sactiv√©e.")

    with tab3:
        st.subheader("Distribution des Scores Elo")
        fig = px.bar(df, x='Titre', y='Elo', color='Nouveaut√©', 
                     title="Classement Elo par Nouveaut√©",
                     color_discrete_map={'low': '#94a3b8', 'medium': '#60a5fa', 'high': '#3b82f6', 'very_high': '#8b5cf6'})
        st.plotly_chart(fig, use_container_width=True)
        
        st.subheader("Relation Qualit√© vs Nouveaut√©")
        # Pr√©parer donn√©es pour scatter plot
        scatter_data = []
        for h in hypotheses:
            if h.reviews:
                last_r = h.reviews[-1]
                scatter_data.append({
                    "Titre": h.title,
                    "Quality": last_r.quality_score,
                    "Novelty Score": last_r.novelty_score,
                    "Elo": h.elo_rating
                })
        if scatter_data:
            df_scatter = pd.DataFrame(scatter_data)
            fig2 = px.scatter(df_scatter, x="Novelty Score", y="Quality", size="Elo", hover_name="Titre",
                              title="Qualit√© vs Nouveaut√© (Taille = Elo)")
            st.plotly_chart(fig2, use_container_width=True)
        else:
            st.info("Pas assez de donn√©es de revue pour le graphique.")

    with tab4:
        st.subheader("Synth√®se de Recherche (Meta-Review)")
        # R√©cup√©rer la derni√®re meta-review si disponible (c'est un dict retourn√© par la fonction, mais pas stock√© directement dans context_memory de mani√®re simple dans le code original, on va simuler un appel ou le r√©cup√©rer si on l'avait stock√©. 
        # Pour l'instant, on va r√©g√©n√©rer une vue rapide ou afficher l'overview)
        
        # Note: Dans l'impl√©mentation actuelle, meta_review est retourn√© mais pas persist√© dans context_memory explicitement sauf via logs.
        # On va demander √† l'agent de le refaire rapidement pour l'affichage
        if st.button("G√©n√©rer le rapport final"):
            with st.spinner("G√©n√©ration du rapport..."):
                try:
                    # Cr√©ation d'une nouvelle boucle pour cet √©v√©nement sp√©cifique si n√©cessaire
                    mr = asyncio.run(cs.meta_review_agent.generate_meta_review(
                        list(cs.context_memory.hypotheses.values()),
                        cs.context_memory.tournament_history,
                        cs.context_memory.research_goal
                    ))
                    st.markdown(mr['research_overview'])
                    
                    st.markdown("### üí° Suggestions d'am√©lioration")
                    for imp in mr['suggested_improvements']:
                        st.markdown(f"- {imp}")
                except RuntimeError as e:
                    st.error(f"Erreur d'ex√©cution asynchrone : {e}. Essayez de relancer l'application.")
                except Exception as e:
                    st.error(f"Une erreur est survenue lors de la g√©n√©ration : {e}")

    with tab5:
        st.subheader("Exporter les donn√©es")
        
        # Pr√©paration du JSON
        json_str = json.dumps({
            "goal": asdict(cs.context_memory.research_goal),
            "literature_context": cs.context_memory.literature_context,
            "hypotheses": [asdict(h) for h in hypotheses]
        }, indent=2, default=str)
        
        st.download_button(
            label="üì• T√©l√©charger le rapport JSON",
            data=json_str,
            file_name="co_scientist_results.json",
            mime="application/json"
        )
